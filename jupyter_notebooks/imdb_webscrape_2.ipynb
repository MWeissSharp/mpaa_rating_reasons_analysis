{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "082a8398",
   "metadata": {},
   "source": [
    "#### Notes\n",
    "- This notebook is using the IMDB IDs collected from the first scrape to retrieve the parental guidance page for each movie\n",
    "- From this page, the rating reason will be scraped (if available) as well as the MPAA Certificate #\n",
    "- This only applies to movies rated something other than \"G\" since G rated movies don't have rating reasons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed184252",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceae030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "first = pd.read_pickle('../data/imdb1992-2001.pkl')\n",
    "second = pd.read_pickle('../data/imdb2002-2009.pkl')\n",
    "third = pd.read_pickle('../data/imdb2010-2018.pkl')\n",
    "fourth = pd.read_pickle('../data/imdb2019-2021.pkl')\n",
    "fifth = pd.read_pickle('../data/imdb2022.pkl')\n",
    "\n",
    "imdb = pd.concat([first, second, third, fourth, fifth])\n",
    "imdb.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c4123d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_ids = imdb.loc[imdb['imdb_mpaas'] != 'G'].reset_index(drop=True)['imdb_ids']\n",
    "len(reason_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826f961d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids = []\n",
    "reasons = []\n",
    "notes = []\n",
    "\n",
    "for r_id in reason_ids:\n",
    "    url = f'https://www.imdb.com/title/{r_id}/parentalguide?ref_=tt_stry_pg'\n",
    "    soup = BS(requests.get(url).text)\n",
    "    try:\n",
    "        reason = soup.find('tr', attrs = {'id': \"mpaa-rating\"}).text.replace('MPAA', '').strip()\n",
    "    except:\n",
    "        reason = \"None\"\n",
    "        \n",
    "    try:\n",
    "        note = re.findall('United States:.+\\n.*(?:certificate|No. )(.+)\\)\\n', soup.find_all('td', attrs = {'class' : ''})[1].text)\n",
    "    except:\n",
    "        note = [\"None\"]\n",
    "    \n",
    "    ids.append(r_id)\n",
    "    reasons.append(reason)\n",
    "    notes.append(note)\n",
    "    \n",
    "    \n",
    "reason_df = pd.DataFrame(\n",
    "    {'imdb_id' : ids,\n",
    "     'rating_reasons' : reasons,\n",
    "     'rating_notes' : notes}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f53038",
   "metadata": {},
   "outputs": [],
   "source": [
    "reason_df.to_pickle('../data/reasons.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cd5b1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
