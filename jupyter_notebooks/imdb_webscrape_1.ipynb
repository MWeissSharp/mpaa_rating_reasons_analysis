{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b003a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup as BS\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241a16cf",
   "metadata": {},
   "source": [
    "#### Notes:\n",
    "- The bulk of the data I want is available on the detailed search result view\n",
    "- I used these criteria for the detailed search:\n",
    "    - Release date between 1/1/92 and 12/31/22, divided into chunks so no one result set is more than 10,000 movies\n",
    "    - MPAA Rating of G, PG, PG-13, or NC-17\n",
    "    - Because of the NC-17 movies, adult content is included\n",
    "    - Types included: Feature, TV Movie, Documentary, Short, and Video\n",
    "- Not all movies have all the elements I'm trying to pull, so there are several elements that have if/else loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13004473",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_page(URL):\n",
    "    \n",
    "    soup = BS(requests.get(URL).text)\n",
    "    \n",
    "    # Get info about number of entries on current page\n",
    "    page_desc = soup.find('div', attrs={'class' : 'desc'}).text.strip()\n",
    "    \n",
    "    # Pull out pertinent info\n",
    "    first_entry = int(re.search('(\\d+,?\\d*)-', page_desc)[1].replace(',', ''))\n",
    "    last_entry = int(re.search('-(\\d+,?\\d*) ', page_desc)[1].replace(',', ''))\n",
    "    entries_on_page = last_entry - (first_entry - 1)\n",
    "    \n",
    "    # Get IMDB ids\n",
    "    ids = [x.get('data-tconst') for x in soup.find_all('div', attrs={'class' : 'ribbonize'})]\n",
    "    \n",
    "    # Get movie titles\n",
    "    titles = [x.find('a').text for x in soup.find_all('h3', attrs={'class' : 'lister-item-header'})]\n",
    "    \n",
    "    # Get MPAA rating\n",
    "    mpaas = []\n",
    "    \n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'certificate'}):\n",
    "            mpaa = soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'certificate'}).text\n",
    "        else:\n",
    "            mpaa = ''\n",
    "        mpaas.append(mpaa)\n",
    "    \n",
    "    # Get movie runtimes\n",
    "    runtimes = []\n",
    "    \n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'runtime'}):\n",
    "            rt = soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'runtime'}).text\n",
    "        else:\n",
    "            rt = ''\n",
    "        runtimes.append(rt)\n",
    "    \n",
    "    # Get movie genres\n",
    "    genres = []\n",
    "    \n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'genre'}):\n",
    "            gens = soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('span', attrs = {'class' : 'genre'}).text.strip()\n",
    "        else:\n",
    "            gens = ''\n",
    "        genres.append(gens)\n",
    "    \n",
    "    # Get movie release years\n",
    "    years = [x.text.strip('()') for x in soup.find_all('span', attrs={'class' : 'lister-item-year text-muted unbold'})]\n",
    "    \n",
    "    # Get IMDB's ratings\n",
    "    ratings = []\n",
    "    \n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('div', attrs={'class' : 'inline-block ratings-imdb-rating'}):\n",
    "            rat = (\n",
    "                soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i]\n",
    "                .find('div', attrs={'class' : 'inline-block ratings-imdb-rating'})\n",
    "                .text.strip().split('\\n| ')\n",
    "            )\n",
    "        else:\n",
    "            rat = ''\n",
    "        ratings.append(rat)\n",
    "    \n",
    "    # Get # votes and US+Canada gross revenue\n",
    "    votes_and_gross = []\n",
    "    \n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('p', attrs = {'class' : 'sort-num_votes-visible'}):\n",
    "            v_and_g = (\n",
    "                soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i]\n",
    "                .find('p', attrs = {'class' : 'sort-num_votes-visible'})\n",
    "                .text.strip().split('\\n| ')\n",
    "            )\n",
    "        else:\n",
    "            v_and_g = ['', '']\n",
    "        votes_and_gross.append(v_and_g)\n",
    "    \n",
    "    # If a movie has a metascore, capture it, if not, put in a placeholder\n",
    "    metas = []\n",
    "\n",
    "    for i in range (0, entries_on_page):\n",
    "        if soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i].find('div', attrs = {'class' : 'inline-block ratings-metascore'}):\n",
    "            meta = (\n",
    "                soup.find_all('div', attrs = {'class' : 'lister-item-content'})[i]\n",
    "                .find('div', attrs = {'class' : 'inline-block ratings-metascore'})\n",
    "                .find('span').text.strip()\n",
    "            )\n",
    "        else:\n",
    "            meta = ''\n",
    "        metas.append(meta)\n",
    "    \n",
    "    # Append results\n",
    "    imdb_ids.extend(ids)\n",
    "    imdb_titles.extend(titles)\n",
    "    imdb_mpaas.extend(mpaas)\n",
    "    imdb_runtimes.extend(runtimes)\n",
    "    imdb_genres.extend(genres)\n",
    "    release_years.extend(years)\n",
    "    imdb_ratings.extend(ratings)\n",
    "    imdb_votes_and_gross.extend(votes_and_gross)\n",
    "    metascores.extend(metas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de897068",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = []\n",
    "imdb_titles = []\n",
    "imdb_mpaas = []\n",
    "imdb_runtimes = []\n",
    "imdb_genres = []\n",
    "release_years = []\n",
    "imdb_ratings = []\n",
    "imdb_votes_and_gross = []\n",
    "metascores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3848d4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=1992-01-01,2001-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250'\n",
    "soup = BS(requests.get(URL).text)\n",
    "total_entries = int(re.search('of (\\d+,?\\d*) ', soup.find('div', attrs={'class' : 'desc'}).text.strip())[1].replace(',', ''))\n",
    "pages = int(total_entries/250)+1\n",
    "\n",
    "for i in range (0, pages):\n",
    "    print(f'page {i} of {pages}')\n",
    "    start_entry = 250 * i + 1\n",
    "    url = f'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=1992-01-01,2001-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250&start={start_entry}'\n",
    "    scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d576c749",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_chunk = pd.DataFrame(\n",
    "    {'imdb_ids' : imdb_ids,\n",
    "     'imdb_titles' : imdb_titles,\n",
    "     'imdb_mpaas' : imdb_mpaas,\n",
    "     'imdb_runtimes' : imdb_runtimes,\n",
    "     'imdb_genres' : imdb_genres,\n",
    "     'release_years' : release_years,\n",
    "     'imdb_ratings' : imdb_ratings,\n",
    "     'imdb_votes_and_gross' : imdb_votes_and_gross,\n",
    "     'metascores' : metascores}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec0739ae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "first_chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35b9e3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_chunk.to_pickle('../data/imdb1992-2001.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "290b2c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = []\n",
    "imdb_titles = []\n",
    "imdb_mpaas = []\n",
    "imdb_runtimes = []\n",
    "imdb_genres = []\n",
    "release_years = []\n",
    "imdb_ratings = []\n",
    "imdb_votes_and_gross = []\n",
    "metascores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9f380d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2002-01-01,2009-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250'\n",
    "soup = BS(requests.get(URL).text)\n",
    "total_entries = int(re.search('of (\\d+,?\\d*) ', soup.find('div', attrs={'class' : 'desc'}).text.strip())[1].replace(',', ''))\n",
    "pages = int(total_entries/250)+1\n",
    "\n",
    "for i in range (0, pages):\n",
    "    current_page = i + 1\n",
    "    print(f'page {current_page} of {pages}')\n",
    "    start_entry = 250 * i + 1\n",
    "    url = f'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2002-01-01,2009-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250&start={start_entry}'\n",
    "    scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a570714",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_chunk = pd.DataFrame(\n",
    "    {'imdb_ids' : imdb_ids,\n",
    "     'imdb_titles' : imdb_titles,\n",
    "     'imdb_mpaas' : imdb_mpaas,\n",
    "     'imdb_runtimes' : imdb_runtimes,\n",
    "     'imdb_genres' : imdb_genres,\n",
    "     'release_years' : release_years,\n",
    "     'imdb_ratings' : imdb_ratings,\n",
    "     'imdb_votes_and_gross' : imdb_votes_and_gross,\n",
    "     'metascores' : metascores}\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83e46b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "second_chunk.to_pickle('../data/imdb2002-2009.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e6ab2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = []\n",
    "imdb_titles = []\n",
    "imdb_mpaas = []\n",
    "imdb_runtimes = []\n",
    "imdb_genres = []\n",
    "release_years = []\n",
    "imdb_ratings = []\n",
    "imdb_votes_and_gross = []\n",
    "metascores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c19b7f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2010-01-01,2018-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250'\n",
    "soup = BS(requests.get(URL).text)\n",
    "total_entries = int(re.search('of (\\d+,?\\d*) ', soup.find('div', attrs={'class' : 'desc'}).text.strip())[1].replace(',', ''))\n",
    "pages = int(total_entries/250)+1\n",
    "\n",
    "for i in range (0, pages):\n",
    "    current_page = i + 1\n",
    "    print(f'page {current_page} of {pages}')\n",
    "    start_entry = 250 * i + 1\n",
    "    url = f'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2010-01-01,2018-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250&start={start_entry}'\n",
    "    scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd3f1f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_chunk = pd.DataFrame(\n",
    "    {'imdb_ids' : imdb_ids,\n",
    "     'imdb_titles' : imdb_titles,\n",
    "     'imdb_mpaas' : imdb_mpaas,\n",
    "     'imdb_runtimes' : imdb_runtimes,\n",
    "     'imdb_genres' : imdb_genres,\n",
    "     'release_years' : release_years,\n",
    "     'imdb_ratings' : imdb_ratings,\n",
    "     'imdb_votes_and_gross' : imdb_votes_and_gross,\n",
    "     'metascores' : metascores}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba914ec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "third_chunk.to_pickle('../data/imdb2010-2018.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5acfb6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = []\n",
    "imdb_titles = []\n",
    "imdb_mpaas = []\n",
    "imdb_runtimes = []\n",
    "imdb_genres = []\n",
    "release_years = []\n",
    "imdb_ratings = []\n",
    "imdb_votes_and_gross = []\n",
    "metascores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53532fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2019-01-01,2022-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250'\n",
    "soup = BS(requests.get(URL).text)\n",
    "total_entries = int(re.search('of (\\d+,?\\d*) ', soup.find('div', attrs={'class' : 'desc'}).text.strip())[1].replace(',', ''))\n",
    "pages = int(total_entries/250)+1\n",
    "\n",
    "for i in range (0, pages):\n",
    "    current_page = i + 1\n",
    "    print(f'page {current_page} of {pages}')\n",
    "    start_entry = 250 * i + 1\n",
    "    url = f'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=2019-01-01,2022-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250&start={start_entry}'\n",
    "    scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9338e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_chunk = pd.DataFrame(\n",
    "    {'imdb_ids' : imdb_ids,\n",
    "     'imdb_titles' : imdb_titles,\n",
    "     'imdb_mpaas' : imdb_mpaas,\n",
    "     'imdb_runtimes' : imdb_runtimes,\n",
    "     'imdb_genres' : imdb_genres,\n",
    "     'release_years' : release_years,\n",
    "     'imdb_ratings' : imdb_ratings,\n",
    "     'imdb_votes_and_gross' : imdb_votes_and_gross,\n",
    "     'metascores' : metascores}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca8ee0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourth_chunk.to_pickle('../data/imdb2019-2022.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1499c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb_ids = []\n",
    "imdb_titles = []\n",
    "imdb_mpaas = []\n",
    "imdb_runtimes = []\n",
    "imdb_genres = []\n",
    "release_years = []\n",
    "imdb_ratings = []\n",
    "imdb_votes_and_gross = []\n",
    "metascores = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea2a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=1991-01-01,1991-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250'\n",
    "soup = BS(requests.get(URL).text)\n",
    "total_entries = int(re.search('of (\\d+,?\\d*) ', soup.find('div', attrs={'class' : 'desc'}).text.strip())[1].replace(',', ''))\n",
    "pages = int(total_entries/250)+1\n",
    "\n",
    "for i in range (0, pages):\n",
    "    current_page = i + 1\n",
    "    print(f'page {current_page} of {pages}')\n",
    "    start_entry = 250 * i + 1\n",
    "    url = f'https://www.imdb.com/search/title/?title_type=feature,tv_movie,documentary,short,video&release_date=1991-01-01,1991-12-31&certificates=US%3AG,US%3APG,US%3APG-13,US%3AR,US%3ANC-17&adult=include&count=250&start={start_entry}'\n",
    "    scrape_page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76071869",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_chunk_a = pd.DataFrame(\n",
    "    {'imdb_ids' : imdb_ids,\n",
    "     'imdb_titles' : imdb_titles,\n",
    "     'imdb_mpaas' : imdb_mpaas,\n",
    "     'imdb_runtimes' : imdb_runtimes,\n",
    "     'imdb_genres' : imdb_genres,\n",
    "     'release_years' : release_years,\n",
    "     'imdb_ratings' : imdb_ratings,\n",
    "     'imdb_votes_and_gross' : imdb_votes_and_gross,\n",
    "     'metascores' : metascores}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9beca909",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_chunk_a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0efd650",
   "metadata": {},
   "outputs": [],
   "source": [
    "additional_chunk_a.to_pickle('../data/imdb1991.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed1fee3e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
